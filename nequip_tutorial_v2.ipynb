{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ingcoder/NequIP-Tutorial/blob/main/nequip_tutorial_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUYhLeLRic61"
      },
      "source": [
        "# NequIP Tutorial \n",
        "This is an implementation of an NequIP energy and force prediction model in python. \n",
        "The trained model is deployed and integrated into LAMMPS MD engine to run an accelerated simulation on a single molecule.\n",
        "Questions? How does the integration works? How to setup LAMMPS simulation? How to determine performance (accuracy) of the model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hHw_NkIwiguA"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# install wandb\n",
        "%pip install wandb\n",
        "# install nequip\n",
        "%git clone --depth 1 \"https://github.com/mir-group/nequip.git\"\n",
        "%pip install nequip/\n",
        "# fix colab imports\n",
        "import site\n",
        "site.main()\n",
        "# set to allow anonymous WandB\n",
        "import os\n",
        "os.environ[\"WANDB_ANONYMOUS\"] = \"must\"\n",
        "import numpy as np \n",
        "import torch \n",
        "from ase.io import read, write\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vyXZ3g1Vjctg"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# compile lammps\n",
        "!git clone -b stable_29Sep2021_update2 --depth 1 https://github.com/lammps/lammps.git\n",
        "!wget \"https://github.com/mir-group/pair_nequip/archive/main.zip\"\n",
        "!unzip -q main.zip\n",
        "!rm main.zip\n",
        "!mv pair_nequip-main pair_nequip\n",
        "!cd pair_nequip && ./patch_lammps.sh ../lammps\n",
        "!pip install mkl mkl-include\n",
        "!cd lammps && mkdir -p build && cd build && cmake ../cmake -DCMAKE_PREFIX_PATH=`python -c 'import torch;print(torch.utils.cmake_prefix_path)'` && make -j4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6dX4lPx0ic63"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import torch\n",
        "torch.set_default_dtype(torch.float32)\n",
        "import numpy as np\n",
        "import logging\n",
        "import pprint\n",
        "from nequip.utils.config import Config\n",
        "from nequip.train.trainer import Trainer\n",
        "from nequip.data import AtomicDataDict\n",
        "from nequip.data import AtomicData\n",
        "from nequip.data import dataset_from_config\n",
        "from ase.io import read, write"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxlC1kWGic64"
      },
      "source": [
        "## Download and Visualize Molecule Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WG-X00uBic64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: no matches found: *.zip\n",
            "zsh:1: no matches found: *.npz\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1020k  100 1020k    0     0   597k      0  0:00:01  0:00:01 --:--:--  598k\n",
            "Archive:  outfile.zip\n",
            "  inflating: toluene_ccsd_t-train.npz  \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._toluene_ccsd_t-train.npz  \n",
            "  inflating: toluene_ccsd_t-test.npz  \n",
            "  inflating: __MACOSX/._toluene_ccsd_t-test.npz  \n",
            "zsh:1: command not found: y\n",
            "toluene.xyz              toluene_ccsd_t-test.npz  toluene_ccsd_t-train.npz\n"
          ]
        }
      ],
      "source": [
        "# Remove existing dataset folders and download molecule dataset\n",
        "!rm -rf ./results/\n",
        "!rm -rf ./benchmark_data\n",
        "!rm *.zip\n",
        "!rm *.npz\n",
        "!mkdir benchmark_data\n",
        "!curl http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip -o outfile.zip\n",
        "!unzip outfile.zip\n",
        "!y | rm -rf __MACOSX outfile outfile.zip\n",
        "!mv toluene* ./benchmark_data\n",
        "!ls benchmark_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "04Y4X3ptnseB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nglview in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (3.0.3)\n",
            "Requirement already satisfied: jupyterlab-widgets in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from nglview) (3.0.7)\n",
            "Requirement already satisfied: ipywidgets>=7 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from nglview) (8.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from nglview) (1.24.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipywidgets>=7->nglview) (8.12.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipywidgets>=7->nglview) (5.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipywidgets>=7->nglview) (6.22.0)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.7 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipywidgets>=7->nglview) (4.0.7)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (5.3.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (0.1.6)\n",
            "Requirement already satisfied: pyzmq>=20 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (25.0.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (1.5.6)\n",
            "Requirement already satisfied: psutil in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (5.9.5)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (6.3)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (1.6.7)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (0.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (23.0)\n",
            "Requirement already satisfied: appnope in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (0.1.3)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets>=7->nglview) (8.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (5.1.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (0.2.0)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (2.15.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (3.0.38)\n",
            "Requirement already satisfied: stack-data in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (0.6.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets>=7->nglview) (0.18.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7->nglview) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7->nglview) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets>=7->nglview) (3.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7->nglview) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets>=7->nglview) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7->nglview) (1.2.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7->nglview) (0.2.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7->nglview) (2.2.1)\n",
            "Requirement already satisfied: six in /usr/local/Caskroom/miniconda/base/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets>=7->nglview) (1.16.0)\n",
            "zsh:1: command not found: jupyter-nbextension\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install nglview\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjupyter-nbextension enable nglview --py --sys-prefix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m output\n\u001b[1;32m      4\u001b[0m output\u001b[38;5;241m.\u001b[39menable_custom_widget_manager()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "!pip install nglview\n",
        "!jupyter-nbextension enable nglview --py --sys-prefix\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "eac4cce28a234719a924f20eef8f645e",
            "5129dce7706d40e290f1424960189cf3",
            "833641b496154da1becf4ca38f1511d4",
            "95bdc18d83ee40d4920eb13ad4a6be44",
            "77ed8e1c8223447da3331ff82ebf8bd8",
            "0c42dcce6aed4b58aa241a2705fcf6c2",
            "5204341de697482e8eafeff7d3c3768f",
            "d2b05882307d48e0a97ce2c4f483fece",
            "63f667a34bfc496ca80a15efde8d8411",
            "ed5745db73444a98a30f4220031785d5",
            "d316354ccd2941ad93bccab340f429e6",
            "9ada3dbf586641a3ade76ee51541d95c",
            "f68864029c6f4a83aed4bbf327a5c3a7"
          ]
        },
        "id": "oywYZsEUic64",
        "outputId": "4c660cb3-8946-4770-ce2f-61f05c50e467"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'super' object has no attribute '_ipython_display_'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnglview\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mase\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read\n\u001b[1;32m      4\u001b[0m atoms \u001b[38;5;241m=\u001b[39m read(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoluene.xyz\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py:4\u001b[0m\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py?line=2'>3</a>\u001b[0m \u001b[39m# for doc\u001b[39;00m\n\u001b[0;32m----> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m adaptor, datafiles, show, widget\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_version\u001b[39;00m \u001b[39mimport\u001b[39;00m get_versions\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/__init__.py?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaptor\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py:13\u001b[0m\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m datafiles\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaptor\u001b[39;00m \u001b[39mimport\u001b[39;00m (ASEStructure, ASETrajectory, BiopythonStructure,\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=4'>5</a>\u001b[0m                       FileStructure, HTMDTrajectory, IODataStructure,\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=5'>6</a>\u001b[0m                       IOTBXStructure, MDAnalysisTrajectory, MDTrajTrajectory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=10'>11</a>\u001b[0m                       RdkitStructure,\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=11'>12</a>\u001b[0m                       TextStructure)\n\u001b[0;32m---> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=12'>13</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwidget\u001b[39;00m \u001b[39mimport\u001b[39;00m NGLWidget\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=14'>15</a>\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=15'>16</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdemo\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=16'>17</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mshow_pdbid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=39'>40</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mshow_biopython\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=40'>41</a>\u001b[0m ]\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/show.py?line=43'>44</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_pdbid\u001b[39m(pdbid, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py:19\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraitlets\u001b[39;00m \u001b[39mimport\u001b[39;00m (Bool, CaselessStrEnum, Dict, Instance, Int, Integer,\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=15'>16</a>\u001b[0m                        List, Unicode, observe, validate)\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtraitlets\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m color, interpolate\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaptor\u001b[39;00m \u001b[39mimport\u001b[39;00m Structure, Trajectory\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/widget.py?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcomponent\u001b[39;00m \u001b[39mimport\u001b[39;00m ComponentViewer\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py:114\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=109'>110</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=110'>111</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mobj\u001b[39m}\u001b[39;00m\u001b[39m must be either list of list or string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=113'>114</a>\u001b[0m ColormakerRegistry \u001b[39m=\u001b[39m _ColormakerRegistry()\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/base.py:10\u001b[0m, in \u001b[0;36m_singleton.<locals>.getinstance\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/base.py?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetinstance\u001b[39m():\n\u001b[1;32m      <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/base.py?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m instances:\n\u001b[0;32m---> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/base.py?line=9'>10</a>\u001b[0m         instances[\u001b[39mcls\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m()\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/base.py?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m instances[\u001b[39mcls\u001b[39m]\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py:47\u001b[0m, in \u001b[0;36m_ColormakerRegistry.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=44'>45</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=45'>46</a>\u001b[0m     get_ipython() \u001b[39m# only display in notebook\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=46'>47</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ipython_display_()\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=47'>48</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNameError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=48'>49</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[0;32m~/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py:54\u001b[0m, in \u001b[0;36m_ColormakerRegistry._ipython_display_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ready:\n\u001b[1;32m     <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/ingrid/PycharmProjects/NequIP/venv/lib/python3.9/site-packages/nglview/color.py?line=53'>54</a>\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_ipython_display_(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '_ipython_display_'"
          ]
        }
      ],
      "source": [
        "# Visualize\n",
        "import nglview\n",
        "from ase.io import read\n",
        "atoms = read('toluene.xyz', index=0)\n",
        "nglview.show_ase(atoms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1hXPDkic64"
      },
      "source": [
        "## Set torch geometric training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7E7Fozklic64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['E', 'name', 'F', 'theory', 'R', 'z', 'type', 'md5']\n",
            "(1000, 15, 3)\n"
          ]
        }
      ],
      "source": [
        "# from nequip.data.dataset import NpzDataset\n",
        "# dataset = NpzDataset('./tutorial_results/')\n",
        "# logging.info(f\"Successfully loaded the data set of type {dataset}...\")\n",
        "npz_files = np.load('benchmark_data/toluene_ccsd_t-train.npz')\n",
        "npz_files['E'].shape\n",
        "npz_files['z']\n",
        "npz_files['name']\n",
        "print(npz_files.files)\n",
        "print(npz_files['R'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xt3vSgYkic65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'BesselBasis_trainable': True,\n",
            " 'PolynomialCutoff_p': 6,\n",
            " 'append': True,\n",
            " 'avg_num_neighbors': 'auto',\n",
            " 'batch_size': 1,\n",
            " 'chemical_embedding_irreps_out': '32x0e',\n",
            " 'chemical_symbols': ['H', 'C'],\n",
            " 'dataset': 'npz',\n",
            " 'dataset_file_name': './benchmark_data/toluene_ccsd_t-train.npz',\n",
            " 'dataset_seed': 456,\n",
            " 'dataset_url': 'http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip',\n",
            " 'default_dtype': 'float32',\n",
            " 'early_stopping_lower_bounds': {'LR': 1e-05},\n",
            " 'early_stopping_patiences': {'validation_loss': 50},\n",
            " 'ema_decay': 0.99,\n",
            " 'ema_use_num_updates': True,\n",
            " 'feature_irreps_hidden': '32x0o + 32x0e + 32x1o + 32x1e',\n",
            " 'invariant_layers': 2,\n",
            " 'invariant_neurons': 64,\n",
            " 'irreps_edge_sh': '0e + 1o',\n",
            " 'key_mapping': {'E': 'total_energy',\n",
            "                 'F': 'forces',\n",
            "                 'R': 'pos',\n",
            "                 'z': 'atomic_numbers'},\n",
            " 'l_max': 1,\n",
            " 'learning_rate': 0.005,\n",
            " 'log_batch_freq': 10,\n",
            " 'log_epoch_freq': 1,\n",
            " 'loss_coeffs': {'forces': 1, 'total_energy': [1, 'PerAtomMSELoss']},\n",
            " 'lr_scheduler_factor': 0.5,\n",
            " 'lr_scheduler_name': 'ReduceLROnPlateau',\n",
            " 'lr_scheduler_patience': 100,\n",
            " 'max_epochs': 10,\n",
            " 'metrics_components': [['forces', 'mae'],\n",
            "                        ['forces', 'rmse'],\n",
            "                        ['forces',\n",
            "                         'mae',\n",
            "                         {'PerSpecies': True, 'report_per_component': False}],\n",
            "                        ['forces',\n",
            "                         'rmse',\n",
            "                         {'PerSpecies': True, 'report_per_component': False}],\n",
            "                        ['total_energy', 'mae'],\n",
            "                        ['total_energy', 'mae', {'PerAtom': True}]],\n",
            " 'metrics_key': 'validation_loss',\n",
            " 'n_train': 100,\n",
            " 'n_val': 50,\n",
            " 'nonlinearity_gates': {'e': 'silu', 'o': 'tanh'},\n",
            " 'nonlinearity_scalars': {'e': 'silu', 'o': 'tanh'},\n",
            " 'nonlinearity_type': 'gate',\n",
            " 'npz_fixed_field_keys': ['atomic_numbers'],\n",
            " 'num_basis': 8,\n",
            " 'num_features': 32,\n",
            " 'num_layers': 4,\n",
            " 'num_types': 2,\n",
            " 'optimizer_amsgrad': False,\n",
            " 'optimizer_name': 'Adam',\n",
            " 'parity': True,\n",
            " 'per_species_rescale_scales': 'dataset_forces_rms',\n",
            " 'per_species_rescale_scales_trainable': False,\n",
            " 'per_species_rescale_shifts': 'dataset_per_atom_total_energy_mean',\n",
            " 'per_species_rescale_shifts_trainable': False,\n",
            " 'r_max': 4.0,\n",
            " 'report_init_validation': True,\n",
            " 'root': 'results/toluene',\n",
            " 'run_name': 'example-run-toluene',\n",
            " 'save_checkpoint_freq': -1,\n",
            " 'save_ema_checkpoint_freq': -1,\n",
            " 'seed': 123,\n",
            " 'shuffle': True,\n",
            " 'train_val_split': 'random',\n",
            " 'use_ema': True,\n",
            " 'use_sc': True,\n",
            " 'validation_batch_size': 1,\n",
            " 'verbose': 'info',\n",
            " 'wandb': False,\n",
            " 'wandb_project': 'toluene-example'}\n"
          ]
        }
      ],
      "source": [
        "# Load config file\n",
        "config = Config.from_file('example.yaml')\n",
        "pprint.pprint(config.as_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hlaPGymPic65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Torch device: cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'num_types': 2,\n",
              " 'irreps_edge_sh': '0e + 1o',\n",
              " 'feature_irreps_hidden': '32x0o + 32x0e + 32x1o + 32x1e',\n",
              " 'chemical_embedding_irreps_out': '32x0e',\n",
              " 'root': 'results/toluene',\n",
              " 'run_name': 'example-run-toluene',\n",
              " 'append': True,\n",
              " 'default_dtype': 'float32',\n",
              " 'r_max': 4.0,\n",
              " 'num_layers': 4,\n",
              " 'l_max': 1,\n",
              " 'parity': True,\n",
              " 'num_features': 32,\n",
              " 'nonlinearity_type': 'gate',\n",
              " 'nonlinearity_scalars': {'e': 'silu', 'o': 'tanh'},\n",
              " 'nonlinearity_gates': {'e': 'silu', 'o': 'tanh'},\n",
              " 'num_basis': 8,\n",
              " 'BesselBasis_trainable': True,\n",
              " 'PolynomialCutoff_p': 6,\n",
              " 'invariant_layers': 2,\n",
              " 'invariant_neurons': 64,\n",
              " 'avg_num_neighbors': 'auto',\n",
              " 'use_sc': True,\n",
              " 'dataset': 'npz',\n",
              " 'dataset_url': 'http://quantum-machine.org/gdml/data/npz/toluene_ccsd_t.zip',\n",
              " 'dataset_file_name': './benchmark_data/toluene_ccsd_t-train.npz',\n",
              " 'key_mapping': {'z': 'atomic_numbers',\n",
              "  'E': 'total_energy',\n",
              "  'F': 'forces',\n",
              "  'R': 'pos'},\n",
              " 'npz_fixed_field_keys': ['atomic_numbers'],\n",
              " 'chemical_symbols': ['H', 'C'],\n",
              " 'wandb': False,\n",
              " 'wandb_project': 'toluene-example',\n",
              " 'early_stopping_patiences': {'validation_loss': 50},\n",
              " 'early_stopping_lower_bounds': {'LR': 1e-05},\n",
              " 'optimizer_amsgrad': False,\n",
              " 'lr_scheduler_patience': 100,\n",
              " 'lr_scheduler_factor': 0.5,\n",
              " 'per_species_rescale_shifts_trainable': False,\n",
              " 'per_species_rescale_scales_trainable': False,\n",
              " 'per_species_rescale_shifts': 'dataset_per_atom_total_energy_mean',\n",
              " 'per_species_rescale_scales': 'dataset_forces_rms'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Instantiate Trainer object trainer with a config file. The trainer handles training as well as call back functions for logging, model saving, and early stopping.\n",
        "trainer = Trainer(model=None, **dict(config))\n",
        "trainer.kwargs\n",
        "\n",
        "# from nequip.train.trainer_wandb import TrainerWandB as Trainer\n",
        "# trainer = Trainer(model=None, **dict(config))\n",
        "# trainer.kwargs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZkJlVCDAic65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing dataset...\n",
            "Loaded data: Batch(batch=[15000], cell=[1000, 3, 3], edge_cell_shift=[154352, 3], edge_index=[2, 154352], forces=[15000, 3], pbc=[1000, 3], pos=[15000, 3], ptr=[1001], total_energy=[1000, 1])\n",
            "    processed data size: ~4.63 MB\n",
            "Cached processed data to disk\n",
            "Done!\n",
            "Successfully loaded the data set of type NpzDataset(1000)...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AtomicData(atom_types=[15, 1], cell=[3, 3], edge_cell_shift=[152, 3], edge_index=[2, 152], forces=[15, 3], pbc=[3], pos=[15, 3], r_max=4.0, total_energy=[1])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset from config file\n",
        "dataset = dataset_from_config(config, prefix='dataset')\n",
        "logging.info(f\"Successfully loaded the data set of type {dataset}...\")\n",
        "next(iter(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xa5ZySe5ic65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['total_energy', 'forces', 'pos'])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.set_dataset(dataset)\n",
        "trainer.dataset_train.get_data()[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uoQ2EYxLic65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forces standard deviation: 30.621034622192383\n",
            "Eneriges standard deiation: 6.097484111785889\n",
            "Energies mean: -169793.3125\n"
          ]
        }
      ],
      "source": [
        "# Normalize training dataset, compute statistics\n",
        "(\n",
        "    (forces_std,),\n",
        "    (energies_mean, energies_std)\n",
        ") = trainer.dataset_train.statistics(\n",
        "    fields=[\n",
        "        AtomicDataDict.FORCE_KEY,\n",
        "        AtomicDataDict.TOTAL_ENERGY_KEY\n",
        "    ],\n",
        "    modes=[\"rms\", \"mean_std\"],\n",
        ")\n",
        "print(f\"Forces standard deviation: {forces_std.item()}\")\n",
        "print(f\"Eneriges standard deiation: {energies_std.item()}\")\n",
        "print(f\"Energies mean: {energies_mean.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LuVt0qEic66"
      },
      "outputs": [],
      "source": [
        "# 1) Todo: Normalize target (energy and forces)\n",
        "# result = trainer.dataset_train.get_data()\n",
        "# energy_minus_mean = result[0]['total_energy'] - energies_mean.numpy()\n",
        "# energy_normalized = energy_minus_mean * energies_std.numpy()\n",
        "# trainer.dataset_train.get_data()[0]['total_energy'] = energy_normalized "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IYB0M5zic66"
      },
      "source": [
        "## Force and Energy Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pVu9cuI_ic66"
      },
      "outputs": [],
      "source": [
        "# Create model\n",
        "from nequip.model._grads import ForceOutput\n",
        "from typing import Optional\n",
        "import logging\n",
        "from e3nn import o3\n",
        "from nequip.data import AtomicDataDict, AtomicDataset\n",
        "from nequip.nn import (\n",
        "    SequentialGraphNetwork,\n",
        "    AtomwiseLinear,\n",
        "    AtomwiseReduce,\n",
        "    ConvNetLayer,\n",
        ")\n",
        "from nequip.nn.embedding import (\n",
        "    OneHotAtomEncoding,\n",
        "    RadialBasisEdgeEncoding,\n",
        "    SphericalHarmonicEdgeAttrs,\n",
        ")\n",
        "\n",
        "from nequip.model import builder_utils\n",
        "\n",
        "def EnergyModel(\n",
        "    config, initialize: bool, dataset: Optional[AtomicDataset] = None\n",
        ") -> SequentialGraphNetwork:\n",
        "    \"\"\"Base default energy model archetecture.\n",
        "\n",
        "    For minimal and full configuration option listings, see ``minimal.yaml`` and ``example.yaml``.\n",
        "    \"\"\"\n",
        "    logging.debug(\"Start building the network model\")\n",
        "\n",
        "    builder_utils.add_avg_num_neighbors(\n",
        "        config=config, initialize=initialize, dataset=dataset\n",
        "    )\n",
        "\n",
        "    num_layers = config.get(\"num_layers\", 3)\n",
        "\n",
        "    layers = {\n",
        "        # -- Encode --\n",
        "        \"one_hot\": OneHotAtomEncoding,\n",
        "        \"spharm_edges\": SphericalHarmonicEdgeAttrs,\n",
        "        \"radial_basis\": RadialBasisEdgeEncoding,\n",
        "        # -- Embed features --\n",
        "        \"chemical_embedding\": AtomwiseLinear,\n",
        "    }\n",
        "\n",
        "    # add convnet layers\n",
        "    # insertion preserves order\n",
        "    for layer_i in range(num_layers):\n",
        "        layers[f\"layer{layer_i}_convnet\"] = ConvNetLayer\n",
        "\n",
        "    # .update also maintains insertion order\n",
        "    layers.update(\n",
        "        {\n",
        "            # TODO: the next linear throws out all L > 0, don't create them in the last layer of convnet\n",
        "            # -- output block --\n",
        "            \"conv_to_output_hidden\": AtomwiseLinear,\n",
        "            \"output_hidden_to_scalar\": (\n",
        "                AtomwiseLinear,\n",
        "                dict(irreps_out=\"1x0e\", out_field=AtomicDataDict.PER_ATOM_ENERGY_KEY),\n",
        "            ),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    layers[\"total_energy_sum\"] = (\n",
        "        AtomwiseReduce,\n",
        "        dict(\n",
        "            reduce=\"sum\",\n",
        "            field=AtomicDataDict.PER_ATOM_ENERGY_KEY,\n",
        "            out_field=AtomicDataDict.TOTAL_ENERGY_KEY,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    return SequentialGraphNetwork.from_parameters(\n",
        "        shared_params=config,\n",
        "        layers=layers,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xae2xNKIic66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GradientOutput(\n",
            "  (func): SequentialGraphNetwork(\n",
            "    (one_hot): OneHotAtomEncoding()\n",
            "    (spharm_edges): SphericalHarmonicEdgeAttrs(\n",
            "      (sh): SphericalHarmonics()\n",
            "    )\n",
            "    (radial_basis): RadialBasisEdgeEncoding(\n",
            "      (basis): BesselBasis()\n",
            "      (cutoff): PolynomialCutoff()\n",
            "    )\n",
            "    (chemical_embedding): AtomwiseLinear(\n",
            "      (linear): Linear(2x0e -> 32x0e | 64 weights)\n",
            "    )\n",
            "    (layer0_convnet): ConvNetLayer(\n",
            "      (equivariant_nonlin): Gate (64x0e+32x1o -> 32x0e+32x1o)\n",
            "      (conv): InteractionBlock(\n",
            "        (linear_1): Linear(32x0e -> 32x0e | 1024 weights)\n",
            "        (fc): FullyConnectedNet[8, 64, 64, 64]\n",
            "        (tp): TensorProduct(32x0e x 1x0e+1x1o -> 32x0e+32x1o | 64 paths | 64 weights)\n",
            "        (linear_2): Linear(32x0e+32x1o -> 64x0e+32x1o | 3072 weights)\n",
            "        (sc): FullyConnectedTensorProduct(32x0e x 2x0e -> 64x0e+32x1o | 4096 paths | 4096 weights)\n",
            "      )\n",
            "    )\n",
            "    (layer1_convnet): ConvNetLayer(\n",
            "      (equivariant_nonlin): Gate (96x0e+32x1o+32x1e -> 32x0e+32x1o+32x1e)\n",
            "      (conv): InteractionBlock(\n",
            "        (linear_1): Linear(32x0e+32x1o -> 32x0e+32x1o | 2048 weights)\n",
            "        (fc): FullyConnectedNet[8, 64, 64, 160]\n",
            "        (tp): TensorProduct(32x0e+32x1o x 1x0e+1x1o -> 64x0e+64x1o+32x1e | 160 paths | 160 weights)\n",
            "        (linear_2): Linear(64x0e+64x1o+32x1e -> 96x0e+32x1o+32x1e | 9216 weights)\n",
            "        (sc): FullyConnectedTensorProduct(32x0e+32x1o x 2x0e -> 96x0e+32x1o+32x1e | 8192 paths | 8192 weights)\n",
            "      )\n",
            "    )\n",
            "    (layer2_convnet): ConvNetLayer(\n",
            "      (equivariant_nonlin): Gate (32x0o+96x0e+32x1o+32x1e -> 32x0o+32x0e+32x1o+32x1e)\n",
            "      (conv): InteractionBlock(\n",
            "        (linear_1): Linear(32x0e+32x1o+32x1e -> 32x0e+32x1o+32x1e | 3072 weights)\n",
            "        (fc): FullyConnectedNet[8, 64, 64, 256]\n",
            "        (tp): TensorProduct(32x0e+32x1o+32x1e x 1x0e+1x1o -> 32x0o+64x0e+96x1o+64x1e | 256 paths | 256 weights)\n",
            "        (linear_2): Linear(32x0o+64x0e+96x1o+64x1e -> 32x0o+96x0e+32x1o+32x1e | 12288 weights)\n",
            "        (sc): FullyConnectedTensorProduct(32x0e+32x1o+32x1e x 2x0e -> 32x0o+96x0e+32x1o+32x1e | 10240 paths | 10240 weights)\n",
            "      )\n",
            "    )\n",
            "    (layer3_convnet): ConvNetLayer(\n",
            "      (equivariant_nonlin): Gate (32x0o+96x0e+32x1o+32x1e -> 32x0o+32x0e+32x1o+32x1e)\n",
            "      (conv): InteractionBlock(\n",
            "        (linear_1): Linear(32x0o+32x0e+32x1o+32x1e -> 32x0o+32x0e+32x1o+32x1e | 4096 weights)\n",
            "        (fc): FullyConnectedNet[8, 64, 64, 320]\n",
            "        (tp): TensorProduct(32x0o+32x0e+32x1o+32x1e x 1x0e+1x1o -> 64x0o+64x0e+96x1o+96x1e | 320 paths | 320 weights)\n",
            "        (linear_2): Linear(64x0o+64x0e+96x1o+96x1e -> 32x0o+96x0e+32x1o+32x1e | 14336 weights)\n",
            "        (sc): FullyConnectedTensorProduct(32x0o+32x0e+32x1o+32x1e x 2x0e -> 32x0o+96x0e+32x1o+32x1e | 12288 paths | 12288 weights)\n",
            "      )\n",
            "    )\n",
            "    (conv_to_output_hidden): AtomwiseLinear(\n",
            "      (linear): Linear(32x0o+32x0e+32x1o+32x1e -> 32x0o+32x0e+32x1o+32x1e | 4096 weights)\n",
            "    )\n",
            "    (output_hidden_to_scalar): AtomwiseLinear(\n",
            "      (linear): Linear(32x0o+32x0e+32x1o+32x1e -> 1x0e | 32 weights)\n",
            "    )\n",
            "    (total_energy_sum): AtomwiseReduce()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "energy_model = EnergyModel(config, initialize=True, dataset=dataset)\n",
        "force_model = ForceOutput(energy_model)\n",
        "print(force_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0wR9ovNtic66"
      },
      "outputs": [],
      "source": [
        "# 2) Todo: Rescale the output\n",
        "# Since we normalized the targets, the model will also learn in this normalized space. To go back to our actual space, \n",
        "# we have to rescale the output. We do this using the RescaleOutput module which wraps a model -- in our case, our force model -- \n",
        "# and rescales its outputs appropriately.\n",
        "from nequip.nn import RescaleOutput\n",
        "final_model = RescaleOutput(\n",
        "    model=force_model, \n",
        "    scale_keys=[AtomicDataDict.TOTAL_ENERGY_KEY, AtomicDataDict.FORCE_KEY],\n",
        "    scale_by=forces_std,\n",
        "    shift_keys=AtomicDataDict.TOTAL_ENERGY_KEY,\n",
        "    shift_by=energies_mean,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wandb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlogin()\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
          ]
        }
      ],
      "source": [
        "# import wandb\n",
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run = wandb.init(\n",
        "#     # Set the project where this run will be logged\n",
        "#     project=\"nequip-tutorial\",\n",
        "#     # Track hyperparameters and run metadata\n",
        "#     config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A8WtQubaic66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Number of weights: 157800\n",
            "Number of trainable weights: 157800\n",
            "! Starting training ...\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      0    10         1.04         1.03       0.0121         24.3           31         22.6         26.2         24.4         26.6         35.4           31         50.6         3.37\n",
            "      0    20        0.565         0.54       0.0251         16.3         22.5         12.5         20.6         16.5           16         28.1         22.1         72.8         4.85\n",
            "      0    30        0.662        0.641       0.0209         19.1         24.5         12.7         26.4         19.6         15.8         31.7         23.7         66.3         4.42\n",
            "      0    40         1.01        0.992       0.0174         23.1         30.5         17.4         29.7         23.5         23.5         36.9         30.2         60.6         4.04\n",
            "      0    50        0.973         0.95       0.0229         22.4         29.8         16.9         28.6         22.7         22.9         36.2         29.5         69.6         4.64\n",
            "\n",
            "\n",
            "  Initialization     #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Initial Validation          0    1.565    0.005         0.94       0.0215        0.961         21.8         29.7         15.2         29.4         22.3           20         37.8         28.9         67.1         4.47\n",
            "Wall time: 1.5662669170001209\n",
            "! Best model        0    0.961\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      1    10        0.805         0.79       0.0157         19.3         27.2         11.4         28.2         19.8         13.8           37         25.4         57.6         3.84\n",
            "      1    20        0.325        0.305       0.0201         12.6         16.9         6.63         19.4           13          8.3         23.1         15.7         65.2         4.35\n",
            "      1    30        0.258        0.242       0.0162         12.1         15.1         9.16         15.4         12.3         10.9         18.7         14.8         58.5          3.9\n",
            "      1    40        0.164        0.164     1.18e-05         9.05         12.4         4.26         14.5          9.4         5.85         17.1         11.5         1.58        0.105\n",
            "      1    50        0.095       0.0853      0.00969         7.03         8.94         5.04         9.31         7.18         6.06         11.4         8.72         45.2         3.01\n",
            "      1    60         0.19        0.185      0.00469         10.5         13.2         7.83         13.5         10.7         8.84         16.8         12.8         31.4          2.1\n",
            "      1    70       0.0645       0.0641     0.000485         6.03         7.75         4.61         7.65         6.13         5.86         9.46         7.66         10.1        0.674\n",
            "      1    80       0.0824       0.0797      0.00275          6.9         8.64         5.23         8.81         7.02         6.81         10.3         8.58         24.1         1.61\n",
            "      1    90         0.13        0.128       0.0019         7.71         10.9         5.38         10.4         7.88          6.7         14.3         10.5           20         1.33\n",
            "      1   100        0.144        0.133        0.011         7.97         11.2         3.82         12.7         8.26         4.98         15.5         10.2         48.1         3.21\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      1    10       0.0918       0.0898        0.002         7.29         9.18          4.8         10.1         7.47            6         11.8          8.9         20.5         1.37\n",
            "      1    20       0.0486       0.0469       0.0017         5.18         6.63         3.66         6.93         5.29         4.58         8.38         6.48         18.9         1.26\n",
            "      1    30       0.0855       0.0843      0.00118         6.87         8.89         4.85         9.19         7.02         6.31         11.1         8.72         15.8         1.05\n",
            "      1    40        0.131         0.13     0.000776         8.49         11.1         6.13         11.2         8.66         7.16         14.3         10.7         12.8        0.853\n",
            "      1    50       0.0913       0.0898      0.00153         6.82         9.17          4.9         9.03         6.96         5.86         11.9         8.87         17.9          1.2\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               1    7.459    0.005         0.29      0.00809        0.298           11         16.5         7.14         15.3         11.2         10.2         21.5         15.9         34.8         2.32\n",
            "! Validation          1    7.459    0.005       0.0825       0.0019       0.0844          6.5         8.79         4.12         9.21         6.67         5.27         11.6         8.42         19.8         1.32\n",
            "Wall time: 7.460413875000086\n",
            "! Best model        1    0.084\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      2    10        0.108       0.0952       0.0125         6.77         9.45         4.16         9.74         6.95         5.36         12.6         8.97         51.3         3.42\n",
            "      2    20       0.0932       0.0895      0.00363         7.17         9.16         4.67           10         7.35         5.46         12.1         8.77         27.7         1.84\n",
            "      2    30       0.0345       0.0315      0.00298         4.52         5.43         4.41         4.64         4.53         5.09          5.8         5.44         25.1         1.67\n",
            "      2    40       0.0488       0.0487     2.98e-05         5.21         6.76         5.19         5.24         5.22         6.44         7.11         6.77          2.5        0.167\n",
            "      2    50       0.0493       0.0491     0.000214         5.59         6.78         6.06         5.06         5.56         7.37         6.04         6.71         6.72        0.448\n",
            "      2    60       0.0195       0.0193     0.000155         3.44         4.26          2.8         4.18         3.49          3.6          4.9         4.25         5.72        0.381\n",
            "      2    70       0.0518       0.0516     0.000186         5.25         6.95         3.25         7.53         5.39          3.8         9.33         6.57         6.27        0.418\n",
            "      2    80       0.0364       0.0363     7.63e-05         4.54         5.83         3.33         5.91         4.62         4.26         7.22         5.74         4.02        0.268\n",
            "      2    90       0.0293       0.0286     0.000706         4.05         5.18         2.91         5.36         4.13         3.51         6.59         5.05         12.2        0.814\n",
            "      2   100       0.0287       0.0282     0.000477         4.31         5.15         4.15         4.49         4.32         4.85         5.46         5.16           10        0.669\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      2    10       0.0513       0.0513     8.56e-06         5.54         6.94         4.55         6.66         5.61         5.23         8.48         6.85         1.34       0.0896\n",
            "      2    20       0.0261        0.026     6.51e-06         3.69         4.94         2.74         4.77         3.76         3.72         6.04         4.88         1.17       0.0781\n",
            "      2    30       0.0352       0.0352     3.07e-05         4.46         5.74         3.77         5.25         4.51         4.79         6.67         5.73         2.55         0.17\n",
            "      2    40       0.0494       0.0493     8.07e-05         5.17          6.8         4.15         6.34         5.25         4.93         8.44         6.68         4.12        0.275\n",
            "      2    50       0.0365       0.0365     1.07e-05         4.45         5.85         3.82         5.16         4.49         4.53         7.07          5.8          1.5          0.1\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               2   13.328    0.005        0.062      0.00179       0.0637         5.64         7.62         4.11          7.4         5.75         5.45         9.51         7.48         13.9        0.927\n",
            "! Validation          2   13.328    0.005       0.0345     2.09e-05       0.0346         4.34         5.69         3.37         5.45         4.41         4.37          6.9         5.63         1.72        0.115\n",
            "Wall time: 13.329049292000036\n",
            "! Best model        2    0.035\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      3    10       0.0329       0.0328     7.23e-06          4.4         5.55         3.72         5.19         4.45         4.35         6.66         5.51         1.23       0.0823\n",
            "      3    20       0.0349        0.034     0.000902         4.32         5.65         3.11         5.71         4.41         3.74         7.23         5.49         13.8         0.92\n",
            "      3    30       0.0162       0.0162      4.7e-06         3.27          3.9         3.02         3.57         3.29         3.51         4.31         3.91            1       0.0667\n",
            "      3    40       0.0134       0.0134     2.95e-05          2.9         3.54         2.57         3.28         2.92         3.12         3.96         3.54          2.5        0.167\n",
            "      3    50       0.0553        0.055     0.000332         5.41         7.18         3.31         7.82         5.56          4.2          9.5         6.85         8.38        0.558\n",
            "      3    60       0.0242       0.0236     0.000547         3.22         4.71         2.85         3.65         3.25         3.45         5.82         4.63         10.8        0.717\n",
            "      3    70       0.0194       0.0193     9.85e-05         3.23         4.26         2.38         4.19         3.29         2.91          5.4         4.15         4.56        0.304\n",
            "      3    80       0.0234       0.0231     0.000285         3.73         4.65         3.11         4.45         3.78         4.19         5.14         4.66         7.75        0.517\n",
            "      3    90        0.085       0.0844     0.000549         6.74          8.9         4.07          9.8         6.93         5.48         11.6         8.56         10.8        0.718\n",
            "      3   100       0.0316       0.0315     0.000122         4.39         5.43         4.67         4.06         4.37         5.76         5.03          5.4         5.08        0.339\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      3    10       0.0295       0.0295     1.04e-06         4.26         5.26         4.12         4.41         4.27         4.72         5.82         5.27        0.469       0.0312\n",
            "      3    20       0.0206       0.0206     1.02e-05         3.09         4.39         2.34         3.95         3.14         3.29         5.38         4.34         1.47       0.0979\n",
            "      3    30       0.0215       0.0215     3.92e-05         3.57         4.49         3.22         3.96         3.59         4.12         4.88          4.5         2.88        0.192\n",
            "      3    40       0.0339       0.0338     6.67e-05         4.49         5.63         3.81         5.27         4.54         4.58         6.63         5.61         3.75         0.25\n",
            "      3    50        0.021        0.021      1.9e-05         3.22         4.44         3.05         3.42         3.23         3.95         4.93         4.44            2        0.133\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               3   19.246    0.005       0.0291     0.000233       0.0293         3.92         5.22         3.25          4.7         3.97         4.26         6.14          5.2         5.71        0.381\n",
            "! Validation          3   19.246    0.005       0.0198     1.44e-05       0.0199         3.29         4.31         2.88         3.77         3.32         3.83         4.81         4.32         1.35       0.0897\n",
            "Wall time: 19.24804333300017\n",
            "! Best model        3    0.020\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      4    10       0.0263       0.0246       0.0017         3.87         4.81         2.52         5.43         3.97         3.08         6.22         4.65           19         1.26\n",
            "      4    20        0.013       0.0129     0.000127         2.82         3.47         2.61         3.06         2.84         3.23         3.73         3.48         5.17        0.345\n",
            "      4    30       0.0167       0.0167     5.51e-06         3.02         3.95         2.71         3.38         3.05         3.15         4.71         3.93         1.08       0.0719\n",
            "      4    40       0.0204       0.0204     5.18e-06         3.63         4.38         3.37         3.92         3.65         3.82         4.94         4.38         1.05       0.0698\n",
            "      4    50       0.0346       0.0345     9.03e-05         4.18         5.69         3.35         5.12         4.24         4.12         7.06         5.59         4.36        0.291\n",
            "      4    60       0.0226       0.0224     0.000145         3.36         4.58          2.4         4.46         3.43         3.14         5.81         4.47         5.53        0.369\n",
            "      4    70       0.0157       0.0156     0.000152         3.07         3.82         2.78         3.39         3.09         3.33         4.32         3.82         5.67        0.378\n",
            "      4    80       0.0194       0.0192     0.000185         2.81         4.25          1.7         4.07         2.89         1.94         5.86          3.9         6.25        0.417\n",
            "      4    90       0.0216        0.021     0.000546         3.68         4.44         2.86         4.61         3.74         3.58         5.25         4.42         10.7        0.716\n",
            "      4   100       0.0102       0.0101     5.95e-05         2.05         3.08         1.27         2.94          2.1         1.61         4.16         2.89         3.55        0.236\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      4    10       0.0248       0.0248     1.09e-05         4.03         4.82         3.59         4.52         4.06         4.12         5.51         4.82         1.52        0.101\n",
            "      4    20       0.0192       0.0192     1.56e-05         3.01         4.24         2.38         3.73         3.05         3.18          5.2         4.19         1.81        0.121\n",
            "      4    30       0.0171        0.017     3.96e-05         3.22         3.99          2.9         3.59         3.24         3.64         4.36            4         2.89        0.193\n",
            "      4    40       0.0278       0.0278     7.06e-05         4.04          5.1         3.41         4.77         4.09         4.22         5.96         5.09         3.86        0.257\n",
            "      4    50       0.0162       0.0162     2.57e-05         2.76         3.89         2.78         2.72         2.75         3.76         4.04          3.9         2.33        0.155\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               4   25.034    0.005        0.023     0.000264       0.0233         3.47         4.64         2.84         4.18         3.51         3.72         5.51         4.62            6          0.4\n",
            "! Validation          4   25.034    0.005       0.0156     1.52e-05       0.0156         2.91         3.83          2.6         3.27         2.94         3.49         4.18         3.83         1.34       0.0892\n",
            "Wall time: 25.03457933300001\n",
            "! Best model        4    0.016\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      5    10       0.0318       0.0314     0.000356         4.06         5.43         3.45         4.75          4.1         4.33         6.46          5.4         8.66        0.577\n",
            "      5    20      0.00845      0.00844     4.78e-06         2.23         2.81         2.55         1.87         2.21         3.11         2.42         2.77            1       0.0667\n",
            "      5    30       0.0179       0.0177     0.000231         3.23         4.07         3.07         3.42         3.24         3.89         4.26         4.08         6.98        0.466\n",
            "      5    40       0.0168       0.0167     8.86e-06         3.27         3.96         2.54         4.11         3.32         2.99         4.84         3.92         1.38       0.0917\n",
            "      5    50       0.0143       0.0141     0.000135         2.73         3.64         2.39         3.11         2.75         3.13         4.14         3.64         5.34        0.356\n",
            "      5    60      0.00934       0.0093     3.31e-05         2.22         2.95         1.53         3.01         2.27          1.9         3.82         2.86         2.64        0.176\n",
            "      5    70       0.0103       0.0103     3.61e-05         2.58         3.11         2.39          2.8         2.59         2.76         3.46         3.11         2.77        0.184\n",
            "      5    80       0.0199       0.0199     2.48e-05         3.42         4.32         2.69         4.25         3.47         3.27         5.26         4.27         2.28        0.152\n",
            "      5    90       0.0111        0.011     5.66e-05         2.77         3.21         2.21          3.4         2.81         2.54         3.84         3.19         3.45         0.23\n",
            "      5   100       0.0276       0.0275     4.06e-05         3.78         5.08         3.28         4.35         3.82         4.18         5.95         5.06         2.92        0.195\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      5    10       0.0213       0.0213     1.28e-05         3.64         4.47         3.31         4.01         3.66         3.79         5.13         4.46         1.64        0.109\n",
            "      5    20       0.0173       0.0173     5.35e-06         2.96         4.02          2.3         3.71            3            3         4.94         3.97         1.06       0.0708\n",
            "      5    30       0.0139       0.0138     1.96e-05         2.85          3.6         2.62         3.12         2.87         3.28         3.93         3.61         2.03        0.135\n",
            "      5    40       0.0217       0.0217     4.77e-05         3.55         4.51         3.13         4.02         3.58         4.06         4.97         4.51         3.17        0.211\n",
            "      5    50       0.0132       0.0131     1.64e-05         2.41         3.51         2.53         2.27          2.4         3.61         3.39          3.5         1.86        0.124\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               5   31.056    0.005       0.0158     9.18e-05       0.0159         2.93         3.85         2.52         3.39         2.96         3.28          4.4         3.84         3.68        0.245\n",
            "! Validation          5   31.056    0.005       0.0127     1.21e-05       0.0127         2.62         3.45         2.38          2.9         2.64          3.2         3.72         3.46          1.2       0.0799\n",
            "Wall time: 31.05856708300007\n",
            "! Best model        5    0.013\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      6    10       0.0153       0.0153     4.55e-07         2.88         3.78         2.76         3.03         2.89         3.66         3.91         3.79        0.312       0.0208\n",
            "      6    20      0.00884      0.00876     7.39e-05         2.18         2.87         2.43          1.9         2.17         3.19         2.45         2.82         3.95        0.264\n",
            "      6    30       0.0215       0.0215     2.23e-05         3.46         4.49         3.01         3.98         3.49         3.98         5.02          4.5         2.17        0.145\n",
            "      6    40      0.00912      0.00911     1.18e-05         2.39         2.92         2.29          2.5          2.4         2.92         2.93         2.92         1.58        0.105\n",
            "      6    50       0.0138       0.0138     8.47e-07         2.84          3.6         2.23         3.54         2.88         2.94         4.23         3.59        0.422       0.0281\n",
            "      6    60      0.00773      0.00755     0.000179          2.2         2.66         1.92         2.52         2.22         2.27         3.05         2.66         6.16         0.41\n",
            "      6    70       0.0126       0.0126     2.24e-06         2.64         3.44         2.66         2.63         2.64         3.46         3.41         3.43        0.688       0.0458\n",
            "      6    80       0.0158       0.0157     0.000112         3.17         3.83         3.22         3.12         3.17         3.89         3.77         3.83         4.88        0.325\n",
            "      6    90       0.0106       0.0106        8e-06         2.46         3.16         2.17         2.78         2.48         2.81         3.51         3.16          1.3       0.0865\n",
            "      6   100       0.0171        0.017     4.31e-05         2.79         3.99         1.62         4.13         2.87         1.95         5.46         3.71         3.02        0.201\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      6    10       0.0184       0.0184     9.79e-06         3.41         4.16         3.28         3.55         3.42         3.74         4.58         4.16         1.44       0.0958\n",
            "      6    20       0.0157       0.0157     7.23e-07         2.92         3.83         2.27         3.66         2.96         2.94         4.65         3.79        0.391        0.026\n",
            "      6    30        0.012        0.012     9.37e-06         2.66         3.36         2.37         2.99         2.68         3.05         3.68         3.36         1.41       0.0938\n",
            "      6    40       0.0178       0.0178     2.93e-05         3.22         4.08         2.97         3.49         3.23         3.81         4.36         4.09         2.48        0.166\n",
            "      6    50       0.0107       0.0107     8.76e-06          2.2         3.16         2.37         2.01         2.19         3.36         2.91         3.14         1.36       0.0906\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               6   37.091    0.005       0.0132     0.000117       0.0133         2.67         3.52         2.33         3.06         2.69         3.06         3.98         3.52         3.87        0.258\n",
            "! Validation          6   37.091    0.005        0.011     9.81e-06        0.011         2.43         3.21         2.22         2.68         2.45         2.99         3.45         3.22         1.08       0.0722\n",
            "Wall time: 37.09185445800017\n",
            "! Best model        6    0.011\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      7    10       0.0136       0.0134     0.000216         2.82         3.54         1.97         3.78         2.88          2.5         4.44         3.47         6.75         0.45\n",
            "      7    20       0.0196       0.0195     0.000113         3.14         4.28         2.48         3.89         3.18          3.1         5.31          4.2         4.88        0.325\n",
            "      7    30       0.0115       0.0113     0.000228         2.67         3.25          2.3          3.1          2.7         2.85         3.65         3.25         6.92        0.461\n",
            "      7    40       0.0279       0.0279     2.56e-05         4.03         5.11         3.64         4.48         4.06         4.31          5.9          5.1         2.33        0.155\n",
            "      7    50       0.0117       0.0115     0.000201         2.64         3.28         2.22         3.13         2.67         2.92         3.64         3.28         6.52        0.434\n",
            "      7    60       0.0105      0.00998     0.000486         2.61         3.06         2.11         3.18         2.64         2.44         3.64         3.04         10.1        0.675\n",
            "      7    70       0.0129       0.0125     0.000483         2.35         3.42         1.79         2.99         2.39         2.49         4.24         3.36         10.1        0.673\n",
            "      7    80        0.019       0.0189     0.000142         3.11         4.21         2.38         3.94         3.16         3.35         5.01         4.18         5.47        0.365\n",
            "      7    90       0.0146       0.0138     0.000769         2.87          3.6         2.96         2.77         2.87         3.66         3.53          3.6         12.7        0.849\n",
            "      7   100      0.00747      0.00701      0.00046         2.02         2.56         1.52          2.6         2.06         1.86         3.18         2.52         9.86        0.657\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      7    10       0.0163       0.0163     8.96e-06         3.24         3.91          3.3         3.18         3.24         3.75         4.09         3.92         1.38       0.0917\n",
            "      7    20       0.0145       0.0145     4.63e-09         2.85         3.69         2.27         3.52         2.89         2.89         4.43         3.66       0.0312      0.00208\n",
            "      7    30       0.0118       0.0118     5.04e-06         2.64         3.32          2.2         3.14         2.67         2.91         3.74         3.33         1.03       0.0688\n",
            "      7    40       0.0154       0.0154     1.84e-05         2.98          3.8         2.74         3.25         2.99         3.61         3.99          3.8         1.97        0.131\n",
            "      7    50      0.00953      0.00953     4.59e-06         2.17         2.99         2.29         2.04         2.16         3.19         2.74         2.97        0.984       0.0656\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               7   42.822    0.005       0.0129     0.000241       0.0132         2.65         3.48         2.26         3.09         2.67         2.95            4         3.48         6.02        0.402\n",
            "! Validation          7   42.822    0.005      0.00989     9.02e-06       0.0099          2.3         3.04          2.1         2.54         2.32         2.84         3.26         3.05         1.06       0.0707\n",
            "Wall time: 42.82316200000014\n",
            "! Best model        7    0.010\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      8    10       0.0134       0.0134     1.34e-06         2.45         3.55         1.72         3.28          2.5         2.25          4.6         3.43        0.531       0.0354\n",
            "      8    20       0.0234       0.0229     0.000473         3.76         4.64         2.89         4.75         3.82         3.32         5.79         4.55         9.98        0.666\n",
            "      8    30      0.00773      0.00773     4.61e-06         2.01         2.69          1.8         2.25         2.03         2.45         2.95          2.7        0.984       0.0656\n",
            "      8    40       0.0138       0.0136     0.000135         2.82         3.57         2.59         3.08         2.84         3.33         3.83         3.58         5.34        0.356\n",
            "      8    50        0.011       0.0108     0.000192         2.58         3.18         2.56         2.61         2.58         3.21         3.15         3.18         6.36        0.424\n",
            "      8    60        0.013        0.013     2.14e-05         2.77         3.49         2.78         2.74         2.76         3.58         3.38         3.48         2.12        0.142\n",
            "      8    70      0.00781      0.00771     9.66e-05         2.25         2.69         2.18         2.32         2.25         2.63         2.76         2.69         4.52        0.301\n",
            "      8    80      0.00734      0.00688     0.000462         1.84         2.54         1.51         2.21         1.86         2.03         3.02         2.52         9.88        0.658\n",
            "      8    90      0.00571      0.00557     0.000136         1.68         2.29         1.16         2.28         1.72         1.52         2.92         2.22         5.36        0.357\n",
            "      8   100      0.00728      0.00727     7.46e-06         2.17         2.61         1.75         2.64          2.2         2.17         3.04          2.6         1.25       0.0833\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      8    10       0.0151       0.0151     1.64e-05         3.09         3.77         3.34         2.81         3.08         3.89         3.62         3.75         1.86        0.124\n",
            "      8    20       0.0134       0.0134     1.58e-06         2.75         3.55         2.22         3.36         2.79         2.84         4.22         3.53        0.578       0.0385\n",
            "      8    30       0.0114       0.0113     1.16e-05         2.55         3.26         2.03         3.14         2.59         2.82          3.7         3.26         1.56        0.104\n",
            "      8    40       0.0134       0.0134     2.43e-05         2.79         3.55         2.53         3.09         2.81         3.39         3.71         3.55         2.27        0.151\n",
            "      8    50      0.00856      0.00855     9.17e-06          2.1         2.83         2.18            2         2.09         2.97         2.67         2.82         1.39       0.0927\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               8   48.580    0.005       0.0109     0.000134       0.0111         2.41          3.2         2.06         2.81         2.44         2.71         3.69          3.2         4.37        0.291\n",
            "! Validation          8   48.580    0.005      0.00904     9.73e-06      0.00905         2.19         2.91         1.99         2.42         2.21         2.72         3.11         2.92         1.03       0.0688\n",
            "Wall time: 48.58195991700018\n",
            "! Best model        8    0.009\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      9    10       0.0108       0.0108     1.99e-05         2.69         3.18          2.5         2.91         2.71         3.04         3.33         3.19         2.05        0.136\n",
            "      9    20       0.0065      0.00648     2.71e-05         1.94         2.46         1.65         2.26         1.96         1.95         2.95         2.45         2.39        0.159\n",
            "      9    30        0.014        0.014     2.65e-05         2.82         3.62          2.3         3.42         2.86         2.87         4.32          3.6         2.36        0.157\n",
            "      9    40       0.0153       0.0153      6.7e-06         2.83         3.78         1.62         4.22         2.92         2.05         5.09         3.57         1.19       0.0792\n",
            "      9    50      0.00878      0.00855     0.000229         2.35         2.83         1.77            3         2.39         2.22          3.4         2.81         6.95        0.464\n",
            "      9    60      0.00867      0.00866     2.56e-06          2.3         2.85         1.88         2.79         2.33         2.39          3.3         2.84        0.734        0.049\n",
            "      9    70      0.00617      0.00589     0.000279         1.78         2.35         1.25         2.39         1.82          1.6         2.99         2.29         7.67        0.511\n",
            "      9    80      0.00953      0.00948     5.04e-05         2.41         2.98         2.18         2.67         2.42          2.8         3.18         2.99         3.27        0.218\n",
            "      9    90       0.0156       0.0156     4.71e-06         2.66         3.83         1.27         4.25         2.76         1.79         5.27         3.53            1       0.0667\n",
            "      9   100        0.029       0.0285     0.000524         3.79         5.17         3.22         4.44         3.83         3.84         6.35          5.1         10.5        0.701\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "      9    10       0.0144       0.0144     1.61e-05         2.98         3.67         3.35         2.56         2.96         3.94         3.33         3.64         1.84        0.123\n",
            "      9    20       0.0124       0.0124     1.11e-06         2.66         3.41         2.18          3.2         2.69         2.79            4         3.39        0.484       0.0323\n",
            "      9    30       0.0111       0.0111     1.04e-05         2.48         3.22         1.94          3.1         2.52         2.76         3.68         3.22         1.48        0.099\n",
            "      9    40       0.0124       0.0124     1.87e-05         2.65         3.41         2.33         3.02         2.67         3.24         3.59         3.42         1.98        0.132\n",
            "      9    50      0.00806      0.00806     7.41e-06         2.05         2.75         2.09            2         2.05         2.83         2.65         2.74         1.25       0.0833\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train               9   54.037    0.005        0.013     9.71e-05       0.0131         2.61         3.49         2.16         3.13         2.64         2.81         4.13         3.47         3.64        0.243\n",
            "! Validation          9   54.037    0.005      0.00849     9.09e-06       0.0085         2.12         2.82          1.9         2.37         2.14         2.62         3.03         2.83         0.99        0.066\n",
            "Wall time: 54.037764917000004\n",
            "! Best model        9    0.009\n",
            "\n",
            "training\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     10    10       0.0203       0.0199     0.000383         3.05         4.32         2.33         3.88         3.11            3         5.45         4.23         8.98        0.599\n",
            "     10    20       0.0109       0.0108     4.98e-05         2.41         3.19         1.89            3         2.45         2.46         3.86         3.16         3.23        0.216\n",
            "     10    30       0.0172       0.0172     3.47e-05         2.87         4.01         2.49         3.31          2.9         2.97         4.94         3.96          2.7         0.18\n",
            "     10    40       0.0107       0.0105     0.000187         2.43         3.14          1.7         3.27         2.49          2.1         4.01         3.06         6.27        0.418\n",
            "     10    50       0.0251       0.0248     0.000307         3.94         4.82         3.35         4.62         3.98         4.13          5.5         4.81         8.05        0.536\n",
            "     10    60      0.00504      0.00497     6.36e-05         1.75         2.16          1.9         1.57         1.74         2.35         1.92         2.13         3.66        0.244\n",
            "     10    70       0.0142       0.0141     4.52e-05         2.67         3.64         2.52         2.83         2.68         3.08         4.19         3.63         3.09        0.206\n",
            "     10    80        0.019        0.019     4.15e-05         3.24         4.22         2.27         4.36         3.31         2.83         5.38          4.1         2.95        0.197\n",
            "     10    90       0.0153       0.0151     0.000222         2.98         3.76         2.52          3.5         3.01         3.14         4.37         3.75         6.84        0.456\n",
            "     10   100      0.00985      0.00978     6.45e-05         2.42         3.03         1.97         2.93         2.45         2.54          3.5         3.02         3.69        0.246\n",
            "\n",
            "validation\n",
            "# Epoch batch         loss       loss_f       loss_e        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "     10    10       0.0156       0.0156     1.11e-05         3.07         3.82         3.42         2.66         3.04          4.1         3.47         3.79         1.53        0.102\n",
            "     10    20       0.0119       0.0119     1.42e-06          2.6         3.34         2.15         3.12         2.64         2.77         3.89         3.33        0.547       0.0365\n",
            "     10    30        0.011       0.0109     1.18e-05         2.44          3.2         1.82         3.15         2.49         2.64         3.74         3.19         1.58        0.105\n",
            "     10    40       0.0121       0.0121     1.72e-05         2.63         3.37         2.25         3.06         2.66         3.11         3.65         3.38         1.91        0.127\n",
            "     10    50      0.00764      0.00763     7.41e-06         2.01         2.67         2.09         1.93         2.01         2.76         2.58         2.67         1.25       0.0833\n",
            "\n",
            "\n",
            "  Train      #    Epoch      wal       LR       loss_f       loss_e         loss        f_mae       f_rmse      H_f_mae      C_f_mae  psavg_f_mae     H_f_rmse     C_f_rmse psavg_f_rmse        e_mae      e/N_mae\n",
            "! Train              10   59.596    0.005       0.0146     0.000135       0.0147          2.8         3.69         2.32         3.35         2.84         2.98         4.37         3.68          4.5          0.3\n",
            "! Validation         10   59.596    0.005      0.00815     9.12e-06      0.00816         2.07         2.76         1.86         2.31         2.09         2.57         2.98         2.77        0.978       0.0652\n",
            "Wall time: 59.598183583000036\n",
            "! Best model       10    0.008\n",
            "! Stop training: max epochs\n",
            "Wall time: 59.61530000000016\n",
            "Cumulative wall time: 59.61530000000016\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "trainer.model = final_model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOGctZHbzxRL"
      },
      "outputs": [],
      "source": [
        "# 3) Todo: Deploy model with python script. !nequip-deploy build --train-dir results/toluene/example-run-toluene toluene-deployed.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrREAbbOxrSw"
      },
      "outputs": [],
      "source": [
        "# 4) Todo: Validate nequip model on test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow54nysbic66"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "POjrwxific66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<numpy.lib.npyio.NpzFile object at 0x29d317940>\n",
            "tensor([6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "atom_types\n"
          ]
        }
      ],
      "source": [
        "# Inference on last frame in dataset\n",
        "toluene_data = np.load(config.dataset_file_name)\n",
        "print(toluene_data)\n",
        "r = toluene_data['R'][25]\n",
        "forces = toluene_data['F'][25]\n",
        "ATOMIC_NUMBERS_KEY = torch.Tensor(torch.from_numpy(toluene_data['z'].astype(np.float32))).to(torch.int64)\n",
        "print(ATOMIC_NUMBERS_KEY)\n",
        "\n",
        "atom_types = (ATOMIC_NUMBERS_KEY == 6).to(torch.int64)\n",
        "print(atom_types)\n",
        "\n",
        "data = AtomicData.from_points(\n",
        "    pos=r,\n",
        "    r_max=config['r_max'], \n",
        "    **{AtomicDataDict.ATOMIC_NUMBERS_KEY: ATOMIC_NUMBERS_KEY,\n",
        "    AtomicDataDict.ATOM_TYPE_KEY: atom_types # torch.zeros_like(ATOMIC_NUMBERS_KEY)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(AtomicDataDict.ATOM_TYPE_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6PSQAQu_ic66"
      },
      "outputs": [],
      "source": [
        "# 5) Todo: Fix RuntimeError: RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
        "# force_model.train();\n",
        "force_model.eval(); \n",
        "pred = force_model(AtomicData.to_AtomicDataDict(data))['forces']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jl2QkR5pic66",
        "outputId": "c5576d41-f6fc-4013-8ed2-44d161a66ccd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot original and predicted force vectors\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.plot(\n",
        "    r[:, 0],\n",
        "    r[:, 1],\n",
        "    '.k',\n",
        "    markersize=10,\n",
        ")\n",
        "\n",
        "plt.quiver(\n",
        "    r[:, 0],\n",
        "    r[:, 1],\n",
        "    pred[:, 0].detach().numpy(),\n",
        "    pred[:, 1].detach().numpy(),\n",
        "    norm=None\n",
        ")\n",
        "\n",
        "plt.quiver(\n",
        "    r[:, 0], \n",
        "    r[:, 1], \n",
        "    forces[:, 0],\n",
        "    forces[:, 1],\n",
        "    color='red', \n",
        "    norm=None\n",
        ")\n",
        "\n",
        "plt.legend(['Positions', 'Predicted', 'True'], prop={'size': 20})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVD6T9I0ic67"
      },
      "source": [
        "## MD Simulation with LAMMPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW5qmHbIic67",
        "outputId": "8e2862bc-6dc7-4bf3-9dc3-9b68ebab253c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory lammps_run: File exists\n"
          ]
        }
      ],
      "source": [
        "# How to setup lammps config file?\n",
        "lammps_input_minimize = \"\"\"\n",
        "units\treal\n",
        "atom_style atomic\n",
        "newton off\n",
        "thermo 1\n",
        "read_data structure.data\n",
        "\n",
        "pair_style\tnequip\n",
        "pair_coeff\t* * ../toluene-deployed.pth C H \n",
        "mass            1 15.9994\n",
        "mass            2 1.00794\n",
        "\n",
        "neighbor 1.0 bin\n",
        "neigh_modify delay 5 every 1\n",
        "\n",
        "minimize 0.0 1.0e-8 10000 1000000\n",
        "write_dump all custom output.dump id type x y z fx fy fz\n",
        "\"\"\"\n",
        "!mkdir lammps_run\n",
        "with open(\"lammps_run/toluene_minimize.in\", \"w\") as f:\n",
        "    f.write(lammps_input_minimize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yG1tDl7oic67"
      },
      "outputs": [],
      "source": [
        "toluene_example = \"\"\"15\n",
        " Lattice=\"100.0 0.0 0.0 0.0 100.0 0.0 0.0 0.0 100.0\" Properties=species:S:1:pos:R:3 -169777.5840406276=T pbc=\"F F F\"\n",
        " C       52.48936904      49.86911725      50.09520748\n",
        " C       51.01088202      49.89609925      50.17978049\n",
        " C       50.36647401      50.04650925      48.96054247\n",
        " C       48.95673398      50.29576626      48.71580846\n",
        " C       48.04533296      50.26023426      49.82589448\n",
        " C       48.70932398      49.85770925      51.01923950\n",
        " C       50.06326400      49.77782925      51.25691751\n",
        " H       52.94467905      50.48672926      50.86545150\n",
        " H       52.89060405      48.87175023      50.14480949\n",
        " H       53.02173405      50.05890725      49.03968247\n",
        " H       51.01439802      50.38234726      48.05314045\n",
        " H       48.80598498      50.64314926      47.68195744\n",
        " H       46.96754695      50.20586626      49.53998848\n",
        " H       48.16716997      49.75850325      51.88622952\n",
        " H       50.45791001      49.55387424      52.15303052\n",
        " \"\"\"\n",
        "\n",
        "with open('toluene.xyz', 'w') as f: \n",
        "    f.write(toluene_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "BGFCfT_5ic67"
      },
      "outputs": [],
      "source": [
        "# Convert molecule xyz file to ASE object\n",
        "atoms = read('toluene.xyz', format='extxyz')\n",
        "\n",
        "# Perturb positions\n",
        "p = atoms.get_positions()\n",
        "p += np.random.rand(15, 3) * 0.5\n",
        "atoms.set_positions(p)\n",
        "atoms.set_pbc(False)\n",
        "\n",
        "# Write to a LAMMPS file\n",
        "write(\"lammps_run/structure.data\", atoms, format=\"lammps-data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-0EZ4vZic67",
        "outputId": "945ec6bf-cb1d-45d0-b9ca-0a641133453f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAMMPS (29 Sep 2021 - Update 2)\n",
            "OMP_NUM_THREADS environment is not set. Defaulting to 1 thread. (src/comm.cpp:98)\n",
            "  using 1 OpenMP thread(s) per MPI task\n",
            "Reading data file ...\n",
            "  orthogonal box = (0.0000000 0.0000000 0.0000000) to (100.00000 100.00000 100.00000)\n",
            "  1 by 1 by 1 MPI processor grid\n",
            "  reading atoms ...\n",
            "  15 atoms\n",
            "  read_data CPU = 0.003 seconds\n",
            "NEQUIP is using device cuda\n",
            "NequIP Coeff: type 1 is element C\n",
            "NequIP Coeff: type 2 is element H\n",
            "Loading model from ../toluene-deployed.pth\n",
            "terminate called after throwing an instance of 'c10::Error'\n",
            "  what():  Unrecognized data format\n",
            "Exception raised from load at ../torch/csrc/jit/serialization/import.cpp:449 (most recent call first):\n",
            "frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x42 (0x7ffb6387f612 in /usr/local/lib/python3.9/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0x5f (0x7ffb6387bd7f in /usr/local/lib/python3.9/dist-packages/torch/lib/libc10.so)\n",
            "frame #2: torch::jit::load(std::string const&, c10::optional<c10::Device>, std::unordered_map<std::string, std::string, std::hash<std::string>, std::equal_to<std::string>, std::allocator<std::pair<std::string const, std::string> > >&) + 0x191 (0x7ffb97779bd1 in /usr/local/lib/python3.9/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: <unknown function> + 0x3d3242 (0x55fbb1e7b242 in ../lammps/build/lmp)\n",
            "frame #4: <unknown function> + 0xcebfe (0x55fbb1b76bfe in ../lammps/build/lmp)\n",
            "frame #5: <unknown function> + 0xd4bae (0x55fbb1b7cbae in ../lammps/build/lmp)\n",
            "frame #6: <unknown function> + 0xd4d55 (0x55fbb1b7cd55 in ../lammps/build/lmp)\n",
            "frame #7: <unknown function> + 0xa963e (0x55fbb1b5163e in ../lammps/build/lmp)\n",
            "frame #8: __libc_start_main + 0xf3 (0x7ffb63116083 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #9: <unknown function> + 0xa9c4e (0x55fbb1b51c4e in ../lammps/build/lmp)\n",
            "\n",
            "[557272b4f01e:21570] *** Process received signal ***\n",
            "[557272b4f01e:21570] Signal: Aborted (6)\n",
            "[557272b4f01e:21570] Signal code:  (-6)\n",
            "[557272b4f01e:21570] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x14420)[0x7ffbac9cf420]\n",
            "[557272b4f01e:21570] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x7ffb6313500b]\n",
            "[557272b4f01e:21570] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x7ffb63114859]\n",
            "[557272b4f01e:21570] [ 3] /lib/x86_64-linux-gnu/libstdc++.so.6(+0x9e911)[0x7ffb634ee911]\n",
            "[557272b4f01e:21570] [ 4] /lib/x86_64-linux-gnu/libstdc++.so.6(+0xaa38c)[0x7ffb634fa38c]\n",
            "[557272b4f01e:21570] [ 5] /lib/x86_64-linux-gnu/libstdc++.so.6(+0xaa3f7)[0x7ffb634fa3f7]\n",
            "[557272b4f01e:21570] [ 6] /lib/x86_64-linux-gnu/libstdc++.so.6(+0xaa6a9)[0x7ffb634fa6a9]\n",
            "[557272b4f01e:21570] [ 7] /usr/local/lib/python3.9/dist-packages/torch/lib/libc10.so(_ZN3c106detail14torchCheckFailEPKcS2_jS2_+0x8a)[0x7ffb6387bdaa]\n",
            "[557272b4f01e:21570] [ 8] /usr/local/lib/python3.9/dist-packages/torch/lib/libtorch_cpu.so(_ZN5torch3jit4loadERKSsN3c108optionalINS3_6DeviceEEERSt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIS1_SsEEE+0x191)[0x7ffb97779bd1]\n",
            "[557272b4f01e:21570] [ 9] ../lammps/build/lmp(+0x3d3242)[0x55fbb1e7b242]\n",
            "[557272b4f01e:21570] [10] ../lammps/build/lmp(+0xcebfe)[0x55fbb1b76bfe]\n",
            "[557272b4f01e:21570] [11] ../lammps/build/lmp(+0xd4bae)[0x55fbb1b7cbae]\n",
            "[557272b4f01e:21570] [12] ../lammps/build/lmp(+0xd4d55)[0x55fbb1b7cd55]\n",
            "[557272b4f01e:21570] [13] ../lammps/build/lmp(+0xa963e)[0x55fbb1b5163e]\n",
            "[557272b4f01e:21570] [14] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3)[0x7ffb63116083]\n",
            "[557272b4f01e:21570] [15] ../lammps/build/lmp(+0xa9c4e)[0x55fbb1b51c4e]\n",
            "[557272b4f01e:21570] *** End of error message ***\n"
          ]
        }
      ],
      "source": [
        "# This isn't working because model hasn't been deployed yet\n",
        "!cd lammps_run/ && ../lammps/build/lmp -in toluene_minimize.in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RoP0D_b069D"
      },
      "outputs": [],
      "source": [
        "# read the final structure back in \n",
        "minimized = read('./lammps_run/output.dump', format='lammps-dump-text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXKstTv20_XF"
      },
      "outputs": [],
      "source": [
        "# get distances of optimized geometry (reference data: CCSD(T) [Psi4, cc-pVDZ])\n",
        "d_12 = minimized.get_distances(1, 2)\n",
        "\n",
        "# reference: https://cccbdb.nist.gov/geom3x.asp?method=6&basis=2, coupled cluster\n",
        "d_12_ccd = 1.4086\n",
        "\n",
        "print('Relative Error in bond length w.r.t. Coupled Cluster from CCCBDB: {:.3f}%'.format((100 * np.abs(d_12 - d_12_ccd) / d_12_ccd)[0]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nequip-kernel",
      "language": "python",
      "name": "nequip-kernel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c42dcce6aed4b58aa241a2705fcf6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5129dce7706d40e290f1424960189cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5204341de697482e8eafeff7d3c3768f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f667a34bfc496ca80a15efde8d8411": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PlayModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PlayModel",
            "_playing": false,
            "_repeat": false,
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PlayView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "interval": 100,
            "layout": "IPY_MODEL_77ed8e1c8223447da3331ff82ebf8bd8",
            "max": 0,
            "min": 0,
            "show_repeat": true,
            "step": 1,
            "style": "IPY_MODEL_0c42dcce6aed4b58aa241a2705fcf6c2",
            "value": 0
          }
        },
        "77ed8e1c8223447da3331ff82ebf8bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833641b496154da1becf4ca38f1511d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "",
            "disabled": false,
            "icon": "compress",
            "layout": "IPY_MODEL_d316354ccd2941ad93bccab340f429e6",
            "style": "IPY_MODEL_9ada3dbf586641a3ade76ee51541d95c",
            "tooltip": ""
          }
        },
        "95bdc18d83ee40d4920eb13ad4a6be44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63f667a34bfc496ca80a15efde8d8411",
              "IPY_MODEL_ed5745db73444a98a30f4220031785d5"
            ],
            "layout": "IPY_MODEL_f68864029c6f4a83aed4bbf327a5c3a7"
          }
        },
        "9ada3dbf586641a3ade76ee51541d95c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d2b05882307d48e0a97ce2c4f483fece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "SliderStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SliderStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": "",
            "handle_color": null
          }
        },
        "d316354ccd2941ad93bccab340f429e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "34px"
          }
        },
        "eac4cce28a234719a924f20eef8f645e": {
          "model_module": "nglview-js-widgets",
          "model_module_version": "3.0.1",
          "model_name": "NGLModel",
          "state": {
            "_camera_orientation": [
              4020.9898043809126,
              -150.87028330772142,
              -638.5107326131491,
              0,
              -655.9686154826251,
              -847.3124120833083,
              -3930.723045040724,
              0,
              12.766109405070944,
              3982.2250864217967,
              -860.5447068609777,
              0,
              -49.994998931884766,
              -49.75750160217285,
              -49.91749954223633,
              1
            ],
            "_camera_str": "orthographic",
            "_dom_classes": [],
            "_gui_theme": null,
            "_ibtn_fullscreen": "IPY_MODEL_833641b496154da1becf4ca38f1511d4",
            "_igui": null,
            "_iplayer": "IPY_MODEL_95bdc18d83ee40d4920eb13ad4a6be44",
            "_model_module": "nglview-js-widgets",
            "_model_module_version": "3.0.1",
            "_model_name": "NGLModel",
            "_ngl_color_dict": {},
            "_ngl_coordinate_resource": {},
            "_ngl_full_stage_parameters": {
              "ambientColor": 14540253,
              "ambientIntensity": 0.2,
              "backgroundColor": "white",
              "cameraEyeSep": 0.3,
              "cameraFov": 40,
              "cameraType": "perspective",
              "clipDist": 10,
              "clipFar": 100,
              "clipNear": 0,
              "fogFar": 100,
              "fogNear": 50,
              "hoverTimeout": 0,
              "impostor": true,
              "lightColor": 14540253,
              "lightIntensity": 1,
              "mousePreset": "default",
              "panSpeed": 1,
              "quality": "medium",
              "rotateSpeed": 2,
              "sampleLevel": 0,
              "tooltip": true,
              "workerDefault": true,
              "zoomSpeed": 1.2
            },
            "_ngl_msg_archive": [
              {
                "args": [
                  {
                    "binary": false,
                    "data": "MODEL     1\nATOM      1    C MOL     1      52.489  49.869  50.095  1.00  0.00           C  \nATOM      2    C MOL     1      51.011  49.896  50.180  1.00  0.00           C  \nATOM      3    C MOL     1      50.366  50.047  48.961  1.00  0.00           C  \nATOM      4    C MOL     1      48.957  50.296  48.716  1.00  0.00           C  \nATOM      5    C MOL     1      48.045  50.260  49.826  1.00  0.00           C  \nATOM      6    C MOL     1      48.709  49.858  51.019  1.00  0.00           C  \nATOM      7    C MOL     1      50.063  49.778  51.257  1.00  0.00           C  \nATOM      8    H MOL     1      52.945  50.487  50.865  1.00  0.00           H  \nATOM      9    H MOL     1      52.891  48.872  50.145  1.00  0.00           H  \nATOM     10    H MOL     1      53.022  50.059  49.040  1.00  0.00           H  \nATOM     11    H MOL     1      51.014  50.382  48.053  1.00  0.00           H  \nATOM     12    H MOL     1      48.806  50.643  47.682  1.00  0.00           H  \nATOM     13    H MOL     1      46.968  50.206  49.540  1.00  0.00           H  \nATOM     14    H MOL     1      48.167  49.759  51.886  1.00  0.00           H  \nATOM     15    H MOL     1      50.458  49.554  52.153  1.00  0.00           H  \nENDMDL\n",
                    "type": "blob"
                  }
                ],
                "kwargs": {
                  "defaultRepresentation": true,
                  "ext": "pdb"
                },
                "methodName": "loadFile",
                "reconstruc_color_scheme": false,
                "target": "Stage",
                "type": "call_method"
              }
            ],
            "_ngl_original_stage_parameters": {
              "ambientColor": 14540253,
              "ambientIntensity": 0.2,
              "backgroundColor": "white",
              "cameraEyeSep": 0.3,
              "cameraFov": 40,
              "cameraType": "perspective",
              "clipDist": 10,
              "clipFar": 100,
              "clipNear": 0,
              "fogFar": 100,
              "fogNear": 50,
              "hoverTimeout": 0,
              "impostor": true,
              "lightColor": 14540253,
              "lightIntensity": 1,
              "mousePreset": "default",
              "panSpeed": 1,
              "quality": "medium",
              "rotateSpeed": 2,
              "sampleLevel": 0,
              "tooltip": true,
              "workerDefault": true,
              "zoomSpeed": 1.2
            },
            "_ngl_repr_dict": {
              "0": {
                "0": {
                  "params": {
                    "aspectRatio": 1.5,
                    "assembly": "default",
                    "bondScale": 0.3,
                    "bondSpacing": 0.75,
                    "clipCenter": {
                      "x": 0,
                      "y": 0,
                      "z": 0
                    },
                    "clipNear": 0,
                    "clipRadius": 0,
                    "colorMode": "hcl",
                    "colorReverse": false,
                    "colorScale": "",
                    "colorScheme": "element",
                    "colorValue": 9474192,
                    "cylinderOnly": false,
                    "defaultAssembly": "",
                    "depthWrite": true,
                    "diffuse": 16777215,
                    "diffuseInterior": false,
                    "disableImpostor": false,
                    "disablePicking": false,
                    "flatShaded": false,
                    "interiorColor": 2236962,
                    "interiorDarkening": 0,
                    "lazy": false,
                    "lineOnly": false,
                    "linewidth": 2,
                    "matrix": {
                      "elements": [
                        1,
                        0,
                        0,
                        0,
                        0,
                        1,
                        0,
                        0,
                        0,
                        0,
                        1,
                        0,
                        0,
                        0,
                        0,
                        1
                      ]
                    },
                    "metalness": 0,
                    "multipleBond": "off",
                    "opacity": 1,
                    "openEnded": true,
                    "quality": "high",
                    "radialSegments": 20,
                    "radiusData": {},
                    "radiusScale": 2,
                    "radiusSize": 0.15,
                    "radiusType": "size",
                    "roughness": 0.4,
                    "sele": "",
                    "side": "double",
                    "sphereDetail": 2,
                    "useInteriorColor": true,
                    "visible": true,
                    "wireframe": false
                  },
                  "type": "ball+stick"
                }
              },
              "1": {
                "0": {
                  "params": {
                    "aspectRatio": 1.5,
                    "assembly": "default",
                    "bondScale": 0.3,
                    "bondSpacing": 0.75,
                    "clipCenter": {
                      "x": 0,
                      "y": 0,
                      "z": 0
                    },
                    "clipNear": 0,
                    "clipRadius": 0,
                    "colorMode": "hcl",
                    "colorReverse": false,
                    "colorScale": "",
                    "colorScheme": "element",
                    "colorValue": 9474192,
                    "cylinderOnly": false,
                    "defaultAssembly": "",
                    "depthWrite": true,
                    "diffuse": 16777215,
                    "diffuseInterior": false,
                    "disableImpostor": false,
                    "disablePicking": false,
                    "flatShaded": false,
                    "interiorColor": 2236962,
                    "interiorDarkening": 0,
                    "lazy": false,
                    "lineOnly": false,
                    "linewidth": 2,
                    "matrix": {
                      "elements": [
                        1,
                        0,
                        0,
                        0,
                        0,
                        1,
                        0,
                        0,
                        0,
                        0,
                        1,
                        0,
                        0,
                        0,
                        0,
                        1
                      ]
                    },
                    "metalness": 0,
                    "multipleBond": "off",
                    "opacity": 1,
                    "openEnded": true,
                    "quality": "high",
                    "radialSegments": 20,
                    "radiusData": {},
                    "radiusScale": 2,
                    "radiusSize": 0.15,
                    "radiusType": "size",
                    "roughness": 0.4,
                    "sele": "",
                    "side": "double",
                    "sphereDetail": 2,
                    "useInteriorColor": true,
                    "visible": true,
                    "wireframe": false
                  },
                  "type": "ball+stick"
                }
              }
            },
            "_ngl_serialize": false,
            "_ngl_version": "2.0.0-dev.36",
            "_ngl_view_id": [
              "EECE9D23-1672-4EE3-98B7-AE8C78DAB480"
            ],
            "_player_dict": {},
            "_scene_position": {},
            "_scene_rotation": {},
            "_synced_model_ids": [],
            "_synced_repr_model_ids": [],
            "_view_count": null,
            "_view_height": "",
            "_view_module": "nglview-js-widgets",
            "_view_module_version": "3.0.1",
            "_view_name": "NGLView",
            "_view_width": "",
            "background": "white",
            "frame": 0,
            "gui_style": null,
            "layout": "IPY_MODEL_5129dce7706d40e290f1424960189cf3",
            "max_frame": 0,
            "n_components": 2,
            "picked": {}
          }
        },
        "ed5745db73444a98a30f4220031785d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "IntSliderModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntSliderModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "IntSliderView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5204341de697482e8eafeff7d3c3768f",
            "max": 0,
            "min": 0,
            "orientation": "horizontal",
            "readout": true,
            "readout_format": "d",
            "step": 1,
            "style": "IPY_MODEL_d2b05882307d48e0a97ce2c4f483fece",
            "value": 0
          }
        },
        "f68864029c6f4a83aed4bbf327a5c3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
